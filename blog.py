from flask import Flask
from playwright.sync_api import sync_playwright
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import os
import openai
import json
import threading

# êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦
def get_worksheet():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON")
    if not creds_json:
        raise ValueError("âŒ GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    creds_dict = json.loads(creds_json)
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    spreadsheet = client.open("BrandPulse_Lotte_Hotel")
    worksheet = spreadsheet.worksheet("BlogData")
    return worksheet

# ChatGPT ê°ì • ë¶„ì„
def analyze_sentiment(text):
    openai.api_key = os.environ.get("OPENAI_API_KEY")
    if not openai.api_key:
        raise ValueError("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    prompt = f"ì•„ë˜ ë¸”ë¡œê·¸ ì œëª©ì— ëŒ€í•œ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ìš”ì•½í•´ì¤˜:\n\nì œëª©: {text}"
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# ë¸”ë¡œê·¸ ìˆ˜ì§‘
def crawl_naver_blog(keyword):
    results = []
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox"])
        page = browser.new_page()
        try:
            print(f"â–¶ï¸ í¬ë¡¤ë§ ì‹œì‘: {keyword}")
            page.goto(f"https://search.naver.com/search.naver?where=view&query={keyword}", timeout=90000)
            page.wait_for_selector("a.api_txt_lines.total_tit", timeout=10000)
            elements = page.query_selector_all("a.api_txt_lines.total_tit")
            for el in elements[:5]:
                title = el.inner_text()
                link = el.get_attribute("href")
                sentiment = analyze_sentiment(title)
                results.append([datetime.now().strftime("%Y-%m-%d"), keyword, title, "-", sentiment, link])
            print(f"âœ… í¬ë¡¤ë§ ì„±ê³µ: {keyword}, {len(results)}ê±´")
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ ({keyword}): {str(e)}")
        finally:
            browser.close()
    return results

# ì‹¤í–‰ ë° ì €ì¥
def run_blog_crawler():
    try:
        print("run_blog_crawler started")
        worksheet = get_worksheet()
        print("worksheet loaded")
        keywords = ["ë¡¯ë°í˜¸í…”", "ì‹ ë¼í˜¸í…”", "ì¡°ì„ í˜¸í…”", "ë² ìŠ¤íŠ¸ì›¨ìŠ¤í„´"]
        for keyword in keywords:
            print(f"crawling {keyword}")
            data = crawl_naver_blog(keyword)
            print(f"data for {keyword}: {data}")
            if data:
                worksheet.append_rows(data, value_input_option="USER_ENTERED")
                print(f"data appended for {keyword}")
            else:
                print(f"no data to append for {keyword}")
    except Exception as e:
        print(f"run_blog_crawler ì˜ˆì™¸: {e}")

# Flask ì•± ì„¤ì •
app = Flask(__name__)

@app.route("/")
def index():
    return "âœ… BrandPulse Blog Crawler Running"

@app.route("/run")
def run():
    print("ğŸ”¥ /run ë¼ìš°íŠ¸ í˜¸ì¶œë¨")
    threading.Thread(target=run_blog_crawler).start()
    return "âœ… BlogData update started"

# ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆ ìë™ ì‹¤í–‰
def start_crawler_once():
    threading.Thread(target=run_blog_crawler, daemon=True).start()

# í•¨ìˆ˜ ì •ì˜ê°€ ëª¨ë‘ ëë‚œ ë’¤ì— í˜¸ì¶œ!
start_crawler_once()

# í™˜ê²½ë³€ìˆ˜ ìƒíƒœ í™•ì¸ìš© ë””ë²„ê·¸ ë¼ìš°íŠ¸
@app.route("/env-debug")
def env_debug():
    val = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON")
    if not val:
        return "GOOGLE_SERVICE_ACCOUNT_JSON is NOT set!", 500
    return f"Length: {len(val)}<br>Start: {val[:100]}<br>End: {val[-100:]}"
